{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhD and Supervisor data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and restructure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# custom functions\n",
    "from src.clean_names_helpers import (\n",
    "    remove_non_person_contributors_and_export,\n",
    "    format_name_to_lastname_firstname, \n",
    "    ensure_and_load_spacy_model, \n",
    "    merge_near_duplicates_on_col,\n",
    "    pivot_per_contributor_to_per_phd\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reloads any modules that are imported, \n",
    "# so that any changes made to the module files are reflected # without needing to restart the Jupyter kernel.\n",
    "# load autoreload module\n",
    "%load_ext autoreload\n",
    "# mode 1 reloads only when an import statement is called. For production\n",
    "# mode 2 reloads before execution of every cell\n",
    "%autoreload 2\n",
    "\n",
    "# limit the number of rows that are shown with printing data frames\n",
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, and if not available, download the spacy nlp model \n",
    "model_name = \"xx_ent_wiki_sm\" # multilingual NER model\n",
    "nlp = ensure_and_load_spacy_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values\n",
    "NROWS = None # None for all\n",
    "YEAR_RANGE = range(2011,2022+1) # Years of interest are 2011 to 2022\n",
    "\n",
    "# names that spacy does not recognize as such\n",
    "# NOTE: Add the verbatim names here, not the standardized target notation \n",
    "# This list can be fed from removed_contributors.csv that is created when running the script\n",
    "WHITELIST = [ \n",
    "    \"Oosterlaan, J.\",\n",
    "    \"Nollet, F.\"\n",
    "    ] \n",
    "\n",
    "# non-people's names that don't get filtered out by spaCy \n",
    "BLACKLIST = [\n",
    "    \"Cardiology\"\n",
    "]\n",
    "\n",
    "removed_contributors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and do basic cleaning\n",
    "pairs_raw = pd.read_csv(\"data/raw/pairs_sups_phds.csv\", nrows=NROWS)\n",
    "pairs_raw = pairs_raw.convert_dtypes() # make sure all integer columns are integer dtype\n",
    "pairs_raw = pairs_raw.query(\n",
    "    \"year in @YEAR_RANGE\"\n",
    ")\n",
    "pairs_raw = pairs_raw.drop_duplicates()\n",
    "pairs_raw = pairs_raw.dropna(subset=['contributor'])\n",
    "\n",
    "pairs_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove contributors that aren't people\n",
    "csv_path = \"data/removed_contributors.csv\"\n",
    "pairs_filtered = remove_non_person_contributors_and_export(pairs_raw, csv_path, nlp, WHITELIST, BLACKLIST)\n",
    "\n",
    "print(f\"{len(pairs_filtered)} columns are left.\")\n",
    "\n",
    "pairs_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize names\n",
    "pairs_std = pairs_filtered.copy()\n",
    "# Apply name standardization to the contributor column\n",
    "pairs_std['contributor'] = pairs_filtered['contributor'].apply(format_name_to_lastname_firstname)\n",
    "\n",
    "pairs_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get one row per PhD with the contributors in columns\n",
    "pubs = pivot_per_contributor_to_per_phd(pairs=pairs_std)\n",
    "\n",
    "# Make naming hopefully a bit clearer\n",
    "pubs.rename(columns={\"author_name\": \"phd_name\"}, inplace=True)\n",
    "\n",
    "pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset for determining the manual gold standard\n",
    "n_rows_gold_standard = 15\n",
    "seed = 42 # fixed seed\n",
    "\n",
    "pubs_raw = pivot_per_contributor_to_per_phd(pairs=pairs_raw)\n",
    "\n",
    "pairs_sampled = pubs_raw.sample(n=n_rows_gold_standard, random_state=seed)\n",
    "\n",
    "print(\n",
    "    f\"Exporting {n_rows_gold_standard} rows of {len(pubs_raw)}.\\n\"\n",
    "    f\"That is {n_rows_gold_standard/len(pubs_raw)*100} percent of the full dataset.\"\n",
    "    )\n",
    "\n",
    "pairs_sampled.to_csv('data/raw/sampled_pubs_for_gold_standard.csv', index=False)\n",
    "\n",
    "pairs_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnose - Check for functional duplicates of PhD candidates\n",
    "\n",
    "In some cases we also get:\n",
    "\n",
    "- The same PhD listed twice under two different affiliations.\n",
    "- PhDs that are listed more than 2 times.\n",
    "- Different versions of the PhDs name (e.g. Podliesna, Svitlana VS Podliesna, S.S.).\n",
    "- Different versions of the same thesis title.\n",
    "\n",
    "C.f. [#46](https://github.com/StefKirsch/clean-and-enrich-phd-supervisor-data/issues/46)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_title = pubs[pubs.duplicated(subset=[\"title\"], keep=False)].sort_values(by=\"title\")\n",
    "duplicates_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_name = pubs[pubs.duplicated(subset=[\"phd_name\"], keep=False)].sort_values(by='phd_name')\n",
    "duplicates_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs.to_csv('data/cleaned/pubs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
