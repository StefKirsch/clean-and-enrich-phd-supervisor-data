{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Alex Extraction and Matching with .search()\n",
    "\n",
    "The goal of this Notebook is look up the PhD students (Authors) contained in the [cleaned](clean_data.ipynb) NARCIS dataset, and\n",
    "1. Confirm they can be found in OpenAlex\n",
    "2. Confirm their affiliation in NARCIS matches the one in OpenAlex\n",
    "2. Confirm they wrote the associated PhD Thesis\n",
    "3. Per author, look up all the contributors (i.e. potential first supervisors) that are listen in the NARCIS dataset and\n",
    "    a. Find all authors that have worked for the same organization at the time the PhD thesis was published (within a 1 year window)\n",
    "    b. xxx\n",
    "\n",
    "\n",
    "The previous version of this notebook written by a Bachelor student was using the `.search_filter()` method of `pyalex`, which does not search alternate spellings of the specified name. In this notebook we are using `search_filter()`, which does not have that problem. See the example code [here](search_parameter_vs_search_filter.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyalex import Works, Authors, Sources, Institutions, Topics, Publishers, Funders, Concepts\n",
    "import pyalex # importing full package seems to be the only way to call `pyalex.config.email = email_address`\n",
    "import pandas as pd\n",
    "from os import path\n",
    "\n",
    "from src.unabbreviate_institutions import unabbreviate_institutions\n",
    "from src.open_alex_helpers import AuthorRelations, find_phd_and_supervisors_in_row, get_supervisors_openalex_ids\n",
    "from src.io_helpers import fetch_supervisors_from_pilot_dataset\n",
    "from src.clean_names_helpers import format_name_to_lastname_firstname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to read of the full dataset.\n",
    "NROWS = 25 # None for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reloads any modules that are imported, \n",
    "# so that any changes made to the module files are reflected # without needing to restart the Jupyter kernel.\n",
    "# load autoreload module\n",
    "%load_ext autoreload\n",
    "# mode 1 reloads only when an import statement is called. For production\n",
    "# mode 2 reloads before execution of every cell\n",
    "%autoreload 2\n",
    "\n",
    "# limit the number of rows that are shown with printing dataframes\n",
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set contact email adress to get to the [polite pool](https://docs.openalex.org/how-to-use-the-api/rate-limits-and-authentication#the-polite-pool). If you are having a premium plan, you can access it via your email address as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contact email adress from file\n",
    "email_file_path = 'contact_email.txt'\n",
    "\n",
    "if path.isfile(email_file_path):\n",
    "    with open(email_file_path, 'r') as file:\n",
    "        email_address = file.read().strip()\n",
    "\n",
    "    # Assign the email address to the pyalex configuration\n",
    "    pyalex.config.email = email_address\n",
    "\n",
    "pyalex.config.email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Cleaned processed NARCIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs_df = pd.read_csv('data/cleaned/pubs.csv')\n",
    "\n",
    "# Take a sample\n",
    "if NROWS == None:\n",
    "    n_sample = len(pubs_df)\n",
    "else:\n",
    "    n_sample = NROWS\n",
    "    \n",
    "#pubs_df = pubs_df.sample(n=n_sample, random_state=42).reset_index(drop=True)\n",
    " \n",
    "pubs_df = pubs_df.head(NROWS) # use head for now because we actually do find some of these PhDs\n",
    "    \n",
    "pubs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace institution abbreviation with names that can be found in OpenAlex\n",
    "pubs_unabbrev_df = unabbreviate_institutions(pubs_df, 'institution')\n",
    "pubs_unabbrev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Priority supervisor list from ResponsibleSupervision pilot\n",
    "\n",
    "This dataset was created during the Responsible Supervision pilot project, see [here](https://github.com/tamarinde/ResponsibleSupervision/tree/main/Pilot-responsible-supervision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = \"https://github.com/tamarinde/ResponsibleSupervision/tree/main/Pilot-responsible-supervision/data/spreadsheets\"\n",
    "csv_path = \"data/output/sups_pilot.csv\"\n",
    "\n",
    "try:\n",
    "    # Attempt to read the supervisors in the pilot dataset from csv_path\n",
    "    # If it fails, we get them again from GitHub\n",
    "    supervisors_ids = get_supervisors_openalex_ids(repo_url, csv_path)\n",
    "    print(\"Unique Supervisors with OpenAlex IDs:\")\n",
    "    print(supervisors_ids)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# NOTE: The problem with this is that I am getting a lot of matches in OA with all the supervisors. But how do I match them with the spelling and ID I will find in my final dataset?\n",
    "# SOLUTION: I will just list all the author IDs here that I come across. We compare those with the IDs in the final dataset, and whenever we have a match we give the bonus points to that supervisor! \n",
    "\n",
    "# Still looking up all the supervisors in OA takes a while and some queries. So I should buffer the result to a csv and only "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for one row\n",
    "\n",
    "if False:\n",
    "    # Assume we are working with the first row of the DataFrame\n",
    "    row = pubs_df.iloc[0]\n",
    "\n",
    "    # Extract necessary fields\n",
    "    phd_name = row['phd_name']\n",
    "    title = row['title']\n",
    "    year = int(row['year'])\n",
    "    institution = row['institution']\n",
    "    contributors = [row[f'contributor_{i}'] for i in range(1, 11) if pd.notna(row[f'contributor_{i}'])]\n",
    "\n",
    "    # Create an instance of AuthorRelations with desired verbosity ('NONE', 'MEDIUM', 'DETAILED')\n",
    "    years_tolerance = -1  # years tolerance\n",
    "    author_relations = AuthorRelations(\n",
    "        phd_name=phd_name,\n",
    "        title=title,\n",
    "        year=year,\n",
    "        institution=institution,\n",
    "        contributors=contributors,\n",
    "        years_tolerance=years_tolerance,\n",
    "        verbosity='DEBUG'\n",
    "    )\n",
    "\n",
    "    # Search for the PhD candidate using both criteria\n",
    "    author_relations.search_phd_candidate(criteria='title')\n",
    "\n",
    "    # Find potential supervisors among the contributors\n",
    "    author_relations.find_potential_supervisors()\n",
    "\n",
    "    # Get the OpenAlex ID pairs\n",
    "    results = author_relations.get_results()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row using DataFrame.apply\n",
    "results_list = pubs_df.apply(find_phd_and_supervisors_in_row, axis=1).tolist()\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df.to_csv('data/output/matched_pairs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
